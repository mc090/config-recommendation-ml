{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b43290f",
   "metadata": {},
   "source": [
    "# Dataset exploration\n",
    "This notebook runs the project pipeline steps in order:\n",
    "1. fetch raw data\n",
    "2. extract structure\n",
    "3. compute features\n",
    "4. build dataset. \n",
    "\n",
    "It shows mocked process of dataset extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4642eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Notebook] Project root: /workspaces/config-recommendation-ml\n",
      "[Notebook] Data directory: /workspaces/config-recommendation-ml/data\n",
      "[Notebook] Configs loaded:\n",
      "{'dataset_filename': 'dataset.csv', 'overwrite': False}\n",
      "{'data_seed': 90, 'sampling_seed': 90, 'training_seed': 90, 'evaluation_seed': 90, 'deterministic': {'force_hash_sorting': True, 'enforce_timestamp_free_ops': True}}\n",
      "[Notebook] Fetching raw data...\n",
      "[fetch_raw] Saved mock raw metadata to /workspaces/config-recommendation-ml/data/raw/raw_metadata.json\n",
      "[Notebook] Extracting structure...\n",
      "[extract_structure] Saved mock structure to /workspaces/config-recommendation-ml/data/interim/structure.json\n",
      "[Notebook] Computing features...\n",
      "[compute_features] Saved mock features to /workspaces/config-recommendation-ml/data/interim/features.json\n",
      "[Notebook] Building dataset...\n",
      "[build_dataset] Mock dataset saved to /workspaces/config-recommendation-ml/data/processed/dataset.csv\n",
      "[Notebook] Pipeline completed (or attempted).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from config_recommendation_ml.data.build_dataset import build_dataset\n",
    "from config_recommendation_ml.data.compute_features import compute_features\n",
    "from config_recommendation_ml.data.extract_structure import extract_structure\n",
    "from config_recommendation_ml.data.fetch_raw import fetch_raw\n",
    "from config_recommendation_ml.utils.config import load_config\n",
    "from config_recommendation_ml.utils.paths import DATA_DIR, PROJECT_ROOT\n",
    "\n",
    "print(\"[Notebook] Project root:\", PROJECT_ROOT)\n",
    "print(\"[Notebook] Data directory:\", DATA_DIR)\n",
    "\n",
    "data_cfg = load_config(\"data\")\n",
    "seeds_cfg = load_config(\"seeds\")\n",
    "\n",
    "print(\"[Notebook] Configs loaded:\")\n",
    "print(data_cfg)\n",
    "print(seeds_cfg)\n",
    "\n",
    "print(\"[Notebook] Fetching raw data...\")\n",
    "fetch_raw()\n",
    "\n",
    "print(\"[Notebook] Extracting structure...\")\n",
    "extract_structure()\n",
    "\n",
    "print(\"[Notebook] Computing features...\")\n",
    "compute_features()\n",
    "\n",
    "print(\"[Notebook] Building dataset...\")\n",
    "build_dataset()\n",
    "\n",
    "print(\"[Notebook] Pipeline completed (or attempted).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141b875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Notebook] Dataset not found after pipeline. Check previous cells for errors.\n"
     ]
    }
   ],
   "source": [
    "dataset_file = DATA_DIR / data_cfg.get(\"dataset_filename\", \"dataset.csv\")\n",
    "dataset_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not dataset_file.exists():\n",
    "    print(\n",
    "        \"[Notebook] Dataset not found after pipeline. Check previous cells for errors.\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"[Notebook] Dataset exists at {dataset_file}\")\n",
    "\n",
    "    df = pd.read_csv(dataset_file)\n",
    "    display(df.head())\n",
    "    print(df.describe())\n",
    "\n",
    "    if \"stars\" in df.columns:\n",
    "        df[\"stars_scaled\"] = df[\"stars\"] / df[\"stars\"].max()\n",
    "        df.hist(column=\"stars_scaled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
